receivers:
  otlp:
    protocols:
      grpc:
        endpoint: otel-collector:4317
      http:
        endpoint: otel-collector:4318

exporters:
  prometheus:
    endpoint: "otel-collector:8889"

  otlp:
    endpoint: jaeger-all-in-one:4317
    tls:
      insecure: true

  debug:
    verbosity: detailed

  otlphttp:
    endpoint: http://loki:3100/otlp/v1/logs

processors:
  # https://github.com/open-telemetry/opentelemetry-collector/tree/main/processor
  batch:
#    send_batch_size: 1000
#    timeout: 10s

  memory_limiter:
    # 80% of maximum memory up to 2G
    limit_mib: 4000
    # 25% of limit up to 2G
    spike_limit_mib: 1000
    check_interval: 5s

  tail_sampling:
    decision_wait: 10s
    num_traces: 100
    expected_new_traces_per_sec: 10
    policies: [
      {
        # Rule 5: always sample if there is an error
        name: sample-error,
        type: and,
        and:
          {
            and_sub_policy:
              [
                {
                  name: trace-status-policy,
                  type: status_code,
                  status_code: { status_codes: [ ERROR ] },
                },
              ],
          },
      },
    ]

extensions:
  health_check:
  pprof:
    endpoint: :1888
  zpages:
    endpoint: :55679

service:
  extensions: [pprof, zpages, health_check]
  pipelines:
    traces:
      receivers: [otlp]
      processors: [batch, memory_limiter]
      exporters: [debug, otlp]
    metrics:
      receivers: [otlp]
      processors: [batch, memory_limiter]
      exporters: [debug, prometheus]
    logs:
      receivers: [otlp]
      processors: [batch, memory_limiter]
      exporters: [debug, otlphttp]
